(window.webpackJsonp=window.webpackJsonp||[]).push([[57],{418:function(s,t,a){"use strict";a.r(t);var n=a(0),e=Object(n.a)({},(function(){var s=this,t=s._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[t("h1",{attrs:{id:"pandas-模块"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pandas-模块"}},[s._v("#")]),s._v(" pandas 模块")]),s._v(" "),t("h2",{attrs:{id:"pandas-简介"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pandas-简介"}},[s._v("#")]),s._v(" Pandas 简介")]),s._v(" "),t("p",[s._v("Pandas（来源于 "),t("em",[s._v("Panel Data")]),s._v("）是基于 NumPy 的一个强大数据分析与处理库。它提供了两个核心数据结构：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("Series")]),s._v("：一维带标签的数组（类似带索引的一列数据）")]),s._v(" "),t("li",[t("strong",[s._v("DataFrame")]),s._v("：二维表格型数据（类似 Excel 表格 / SQL 表）")])]),s._v(" "),t("p",[s._v("Pandas 在数据清洗、分析、特征工程、金融建模等领域应用广泛，是 Python 数据科学与机器学习的核心库之一。")]),s._v(" "),t("p",[s._v("特点包括：")]),s._v(" "),t("ul",[t("li",[t("strong",[s._v("高效的数据结构")]),s._v("：Series 和 DataFrame 基于 NumPy，支持高效存储与计算")]),s._v(" "),t("li",[t("strong",[s._v("灵活的数据索引与切片")]),s._v("：支持按标签（label）、位置（position）访问数据")]),s._v(" "),t("li",[t("strong",[s._v("丰富的数据操作")]),s._v("：分组（groupby）、聚合（aggregate）、透视表（pivot_table）等")]),s._v(" "),t("li",[t("strong",[s._v("数据清洗与处理")]),s._v("：缺失值处理、数据类型转换、字符串与时间序列处理")]),s._v(" "),t("li",[t("strong",[s._v("文件读写能力")]),s._v("：支持 CSV、Excel、SQL、JSON 等多种格式的高效读写")]),s._v(" "),t("li",[t("strong",[s._v("与其他科学计算库兼容")]),s._v("：可与 NumPy、Matplotlib、Scikit-learn 等无缝结合")])]),s._v(" "),t("h2",{attrs:{id:"📌-pandas-常用方法-方法签名-参数解释"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#📌-pandas-常用方法-方法签名-参数解释"}},[s._v("#")]),s._v(" 📌 Pandas 常用方法（方法签名 + 参数解释）")]),s._v(" "),t("h3",{attrs:{id:"创建对象"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#创建对象"}},[s._v("#")]),s._v(" 创建对象")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("pd.Series(data=None, index=None, dtype=None, name=None, copy=False)")]),s._v("\n→ 创建一维数组结构。\n"),t("ul",[t("li",[t("code",[s._v("data")]),s._v("：数据，可为list/ndarray/dict等")]),s._v(" "),t("li",[t("code",[s._v("index")]),s._v("：索引标签")]),s._v(" "),t("li",[t("code",[s._v("dtype")]),s._v("：数据类型")]),s._v(" "),t("li",[t("code",[s._v("name")]),s._v("：Series 名称")]),s._v(" "),t("li",[t("code",[s._v("copy")]),s._v("：是否复制数据")])])]),s._v(" "),t("li",[t("code",[s._v("pd.DataFrame(data=None, index=None, columns=None, dtype=None, copy=False)")]),s._v("\n→ 创建二维表格结构。\n"),t("ul",[t("li",[t("code",[s._v("data")]),s._v("：二维数据（dict/ndarray等）")]),s._v(" "),t("li",[t("code",[s._v("index")]),s._v("：行索引")]),s._v(" "),t("li",[t("code",[s._v("columns")]),s._v("：列索引")]),s._v(" "),t("li",[t("code",[s._v("dtype")]),s._v("：数据类型")])])])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"查看信息"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#查看信息"}},[s._v("#")]),s._v(" 查看信息")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("df.head(n=5)")]),s._v("\n→ 返回前 n 行。")]),s._v(" "),t("li",[t("code",[s._v("df.tail(n=5)")]),s._v("\n→ 返回后 n 行。")]),s._v(" "),t("li",[t("code",[s._v("df.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None)")]),s._v("\n→ 显示数据表概况。")]),s._v(" "),t("li",[t("code",[s._v("df.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)")]),s._v("\n→ 生成数值型列的统计信息。")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"选择与切片"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#选择与切片"}},[s._v("#")]),s._v(" 选择与切片")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("df.loc[row_indexer, col_indexer]")]),s._v("\n→ 按 "),t("strong",[s._v("标签")]),s._v(" 选择数据。")]),s._v(" "),t("li",[t("code",[s._v("df.iloc[row_indexer, col_indexer]")]),s._v("\n→ 按 "),t("strong",[s._v("位置")]),s._v(" 选择数据。")]),s._v(" "),t("li",[t("code",[s._v("df.query(expr, inplace=False, **kwargs)")]),s._v("\n→ 用表达式筛选数据。\n"),t("ul",[t("li",[t("code",[s._v("expr")]),s._v("：字符串表达式（如 "),t("code",[s._v('"col > 3 & col < 10"')]),s._v("）")]),s._v(" "),t("li",[t("code",[s._v("inplace")]),s._v("：是否原地修改")])])])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"增删改"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#增删改"}},[s._v("#")]),s._v(" 增删改")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("df.drop(labels=None, axis=0, index=None, columns=None, inplace=False)")]),s._v("\n→ 删除行或列。\n"),t("ul",[t("li",[t("code",[s._v("labels")]),s._v("：要删除的行/列名")]),s._v(" "),t("li",[t("code",[s._v("axis")]),s._v("：0=行, 1=列")]),s._v(" "),t("li",[t("code",[s._v("inplace")]),s._v("：是否原地修改")])])]),s._v(" "),t("li",[t("code",[s._v("df.rename(mapper=None, index=None, columns=None, inplace=False)")]),s._v("\n→ 重命名行/列。\n"),t("ul",[t("li",[t("code",[s._v("columns")]),s._v("：字典，旧列名→新列名")]),s._v(" "),t("li",[t("code",[s._v("inplace")]),s._v("：是否原地修改")])])])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"缺失值处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#缺失值处理"}},[s._v("#")]),s._v(" 缺失值处理")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("df.isnull()")]),s._v("\n→ 返回布尔值 DataFrame，标记缺失值。")]),s._v(" "),t("li",[t("code",[s._v("df.fillna(value=None, method=None, inplace=False, limit=None)")]),s._v("\n→ 填充缺失值。\n"),t("ul",[t("li",[t("code",[s._v("value")]),s._v("：填充值")]),s._v(" "),t("li",[t("code",[s._v("method")]),s._v("：填充方式（'ffill' 向前填充, 'bfill' 向后填充）")])])]),s._v(" "),t("li",[t("code",[s._v("df.dropna(axis=0, how='any', inplace=False)")]),s._v("\n→ 删除含缺失值的行/列。\n"),t("ul",[t("li",[t("code",[s._v("axis")]),s._v("：0=行, 1=列")]),s._v(" "),t("li",[t("code",[s._v("how")]),s._v("：'any'=任意NaN删除, 'all'=全NaN删除")])])])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"重复值处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#重复值处理"}},[s._v("#")]),s._v(" 重复值处理")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("df.duplicated(subset=None, keep='first')")]),s._v("\n→ 返回布尔Series，标记重复行。")]),s._v(" "),t("li",[t("code",[s._v("df.drop_duplicates(subset=None, keep='first', inplace=False)")]),s._v("\n→ 删除重复行。\n"),t("ul",[t("li",[t("code",[s._v("subset")]),s._v("：指定检查的列")]),s._v(" "),t("li",[t("code",[s._v("keep")]),s._v("：保留哪一个（'first' / 'last' / False 全删）")])])])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"分组与聚合"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#分组与聚合"}},[s._v("#")]),s._v(" 分组与聚合")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("df.groupby(by=None, axis=0, as_index=True)")]),s._v("\n→ 分组对象。\n"),t("ul",[t("li",[t("code",[s._v("by")]),s._v("：列名/函数/数组")]),s._v(" "),t("li",[t("code",[s._v("as_index")]),s._v("：是否返回索引为分组键")])])]),s._v(" "),t("li",[t("code",[s._v("grouped.agg(func=None, *args, **kwargs)")]),s._v("\n→ 多函数聚合。")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"排序"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#排序"}},[s._v("#")]),s._v(" 排序")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("df.sort_values(by, axis=0, ascending=True, inplace=False)")]),s._v("\n→ 按列值排序。\n"),t("ul",[t("li",[t("code",[s._v("by")]),s._v("：列名")]),s._v(" "),t("li",[t("code",[s._v("ascending")]),s._v("：是否升序")])])]),s._v(" "),t("li",[t("code",[s._v("df.sort_index(axis=0, ascending=True, inplace=False)")]),s._v("\n→ 按索引排序。")])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"合并拼接"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#合并拼接"}},[s._v("#")]),s._v(" 合并拼接")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("pd.concat(objs, axis=0, join='outer', ignore_index=False)")]),s._v("\n→ 沿某维拼接对象。\n"),t("ul",[t("li",[t("code",[s._v("objs")]),s._v("：列表/字典")]),s._v(" "),t("li",[t("code",[s._v("axis")]),s._v("：0=纵向, 1=横向")])])]),s._v(" "),t("li",[t("code",[s._v("pd.merge(left, right, how='inner', on=None, left_on=None, right_on=None)")]),s._v("\n→ 类似SQL join的合并。\n"),t("ul",[t("li",[t("code",[s._v("how")]),s._v("：'inner' / 'outer' / 'left' / 'right'")]),s._v(" "),t("li",[t("code",[s._v("on")]),s._v("：公共列")])])])]),s._v(" "),t("hr"),s._v(" "),t("h3",{attrs:{id:"输入输出"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#输入输出"}},[s._v("#")]),s._v(" 输入输出")]),s._v(" "),t("ul",[t("li",[t("code",[s._v("pd.read_csv(filepath, sep=',', header='infer', encoding=None)")]),s._v("\n→ 从 CSV 文件读取数据。")]),s._v(" "),t("li",[t("code",[s._v("df.to_csv(path, sep=',', index=True, encoding='utf-8')")]),s._v("\n→ 保存为 CSV。")]),s._v(" "),t("li",[t("code",[s._v("pd.read_excel(io, sheet_name=0)")]),s._v("\n→ 读取 Excel。")]),s._v(" "),t("li",[t("code",[s._v("df.to_excel(excel_writer, sheet_name='Sheet1', index=True)")]),s._v("\n→ 保存为 Excel。")])]),s._v(" "),t("h2",{attrs:{id:"pandas-主要方法与功能示例"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#pandas-主要方法与功能示例"}},[s._v("#")]),s._v(" pandas 主要方法与功能示例")]),s._v(" "),t("p",[s._v("在使用pandas之前，需要确保已经"),t("code",[s._v("import")])]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" pandas "),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" pd\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_1-pandas-认识-series-与-dataframe"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-pandas-认识-series-与-dataframe"}},[s._v("#")]),s._v(" 1. pandas 认识：Series 与 DataFrame")]),s._v(" "),t("h4",{attrs:{id:"_1-1-series"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-1-series"}},[s._v("#")]),s._v(" 1.1 Series")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 用列表创建 Series（带默认索引 0,1,2...）")]),s._v("\ns "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Series"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 0    10")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1    20")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2    30")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 3    40")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# dtype: int64")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 用自定义索引")]),s._v("\ns2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Series"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" index"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：1")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("loc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：2")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("iloc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：2")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 从 numpy 数组创建 Series（共享底层数据）")]),s._v("\narr "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("array"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("7")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ns3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Series"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("arr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 修改原数组也影响 Series")]),s._v("\narr"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("100")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br")])]),t("h4",{attrs:{id:"_1-2-用字典创建-series"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_1-2-用字典创建-series"}},[s._v("#")]),s._v(" 1.2 用字典创建 Series")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("d "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'张三'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("18")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'sex'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'男'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),s._v("\ns_dict "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("Series"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("d"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("s_dict"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# name    张三")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# age       18")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# sex       男")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# dtype: object")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_2-dataframe"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_2-dataframe"}},[s._v("#")]),s._v(" 2. DataFrame")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 用字典创建 DataFrame（每个键对应一列）")]),s._v("\ndf "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataFrame"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Alice'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Bob'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Charlie'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("25")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("35")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'score'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("88.5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("92.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("85.0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#       name  age  score")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 0    Alice   25   88.5")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 1      Bob   30   92.0")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 2  Charlie   35   85.0")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 查看属性")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("shape"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("       "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：(3, 3)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("columns"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("     "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：Index(['name', 'age', 'score'], dtype='object')")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("index"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("       "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：RangeIndex(start=0, stop=3, step=1)")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dtypes"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("      "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出每列的数据类型")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 访问列与行")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'name'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("        "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 这会返回一个 Series")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("loc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("         "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 第 1 行数据（标签位置）")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("iloc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 用位置切片：前两行，前两列")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br"),t("span",{staticClass:"line-number"},[s._v("19")]),t("br"),t("span",{staticClass:"line-number"},[s._v("20")]),t("br"),t("span",{staticClass:"line-number"},[s._v("21")]),t("br"),t("span",{staticClass:"line-number"},[s._v("22")]),t("br"),t("span",{staticClass:"line-number"},[s._v("23")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_3-基本操作-增、删、改、查"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_3-基本操作-增、删、改、查"}},[s._v("#")]),s._v(" 3. 基本操作：增、删、改、查")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 新增列")]),s._v("\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'newcol'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("*")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 删除列")]),s._v("\ndf2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("drop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("columns"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'newcol'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 修改值")]),s._v("\ndf"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("at"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'age'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("31")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("loc"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 条件过滤 / 布尔索引")]),s._v("\ndf_filtered "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("df"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'score'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v(">")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("90")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_filtered"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_4-缺失值-重复值处理"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_4-缺失值-重复值处理"}},[s._v("#")]),s._v(" 4. 缺失值 & 重复值处理")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 构造带 NaN 的 DataFrame")]),s._v("\ndf_missing "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataFrame"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'A'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nan"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'B'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" np"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("nan"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_missing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 检查缺失值")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_missing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("isnull"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_missing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("isnull"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 填充缺失值")]),s._v("\ndf_fill0 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df_missing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fillna"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_fill0"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 删除含缺失值的行/列")]),s._v("\ndf_drop "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df_missing"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("dropna"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("axis"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 删除行")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_drop"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br"),t("span",{staticClass:"line-number"},[s._v("18")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_5-分组与聚合-groupby"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_5-分组与聚合-groupby"}},[s._v("#")]),s._v(" 5. 分组与聚合（GroupBy）")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 示例 DataFrame")]),s._v("\ndf3 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataFrame"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'key'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'A'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'B'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'A'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'B'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'value'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("25")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\ngrouped "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df3"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("groupby"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'key'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("grouped"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),t("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("sum")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出：")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#      value")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# key       ")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# A        25")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# B        45")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("grouped"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'value'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mean"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 输出平均值")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_6-合并-连接-拼接"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_6-合并-连接-拼接"}},[s._v("#")]),s._v(" 6. 合并 / 连接 / 拼接")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("df1 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataFrame"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'x'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'a'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'b'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'c'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndf2 "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataFrame"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("2")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("4")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'y'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("20")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("30")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("40")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 内连接（类似 SQL 的 inner join）")]),s._v("\ndf_join "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("merge"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" df2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" on"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" how"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'inner'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_join"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 外连接")]),s._v("\ndf_outer "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("merge"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" df2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" on"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'id'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" how"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'outer'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_outer"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 拼接（上下 / 左右方向）")]),s._v("\ndf_vert "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("concat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("df1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" df2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" ignore_index"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("True")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_vert"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\ndf_horiz "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("concat"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("df1"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" df2"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" axis"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_horiz"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br"),t("span",{staticClass:"line-number"},[s._v("14")]),t("br"),t("span",{staticClass:"line-number"},[s._v("15")]),t("br"),t("span",{staticClass:"line-number"},[s._v("16")]),t("br"),t("span",{staticClass:"line-number"},[s._v("17")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_7-时间序列操作-简要"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_7-时间序列操作-简要"}},[s._v("#")]),s._v(" 7. 时间序列操作（简要）")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[s._v("dates "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("date_range"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2025-01-01'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" periods"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("6")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" freq"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'D'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndf_ts "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("DataFrame"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("{")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'date'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" dates"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("\n    "),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'value'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("12")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("11")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("15")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("14")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" "),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("13")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("}")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\ndf_ts "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" df_ts"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("set_index"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'date'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_ts"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 重采样 / 滚动窗口")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_ts"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("resample"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'2D'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mean"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("   "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 每两天取平均")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("df_ts"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("rolling"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("window"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token number"}},[s._v("3")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("mean"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("  "),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 滑动窗口均值")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br")])]),t("hr"),s._v(" "),t("h3",{attrs:{id:"_8-读取-存储数据"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#_8-读取-存储数据"}},[s._v("#")]),s._v(" 8. 读取 / 存储数据")]),s._v(" "),t("div",{staticClass:"language-python line-numbers-mode"},[t("pre",{pre:!0,attrs:{class:"language-python"}},[t("code",[t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 读取 CSV")]),s._v("\ndf_csv "),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" pd"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("read_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'data.csv'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 写入 CSV")]),s._v("\ndf_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("to_csv"),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),t("span",{pre:!0,attrs:{class:"token string"}},[s._v("'out.csv'")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" index"),t("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),t("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("False")]),t("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 读取 Excel")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# df_excel = pd.read_excel('data.xlsx', sheet_name='Sheet1')")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 写入 Excel")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# df_excel.to_excel('out.xlsx', index=False)")]),s._v("\n\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# 读取 / 写入 JSON")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# df_json = pd.read_json('data.json')")]),s._v("\n"),t("span",{pre:!0,attrs:{class:"token comment"}},[s._v("# df_csv.to_json('out.json')")]),s._v("\n")])]),s._v(" "),t("div",{staticClass:"line-numbers-wrapper"},[t("span",{staticClass:"line-number"},[s._v("1")]),t("br"),t("span",{staticClass:"line-number"},[s._v("2")]),t("br"),t("span",{staticClass:"line-number"},[s._v("3")]),t("br"),t("span",{staticClass:"line-number"},[s._v("4")]),t("br"),t("span",{staticClass:"line-number"},[s._v("5")]),t("br"),t("span",{staticClass:"line-number"},[s._v("6")]),t("br"),t("span",{staticClass:"line-number"},[s._v("7")]),t("br"),t("span",{staticClass:"line-number"},[s._v("8")]),t("br"),t("span",{staticClass:"line-number"},[s._v("9")]),t("br"),t("span",{staticClass:"line-number"},[s._v("10")]),t("br"),t("span",{staticClass:"line-number"},[s._v("11")]),t("br"),t("span",{staticClass:"line-number"},[s._v("12")]),t("br"),t("span",{staticClass:"line-number"},[s._v("13")]),t("br")])])])}),[],!1,null,null,null);t.default=e.exports}}]);