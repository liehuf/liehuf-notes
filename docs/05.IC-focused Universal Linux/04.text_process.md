---
title: Linux 04.Linux的文本处理
date: 2026-02-21 22:00:00
permalink: /pages/Linux_04/
---

# Linux 文本处理基础（grep / cut / sort / uniq / awk / sed）

> 本文基于常见日志文本与结构化分隔文件，梳理 Linux 下最核心的文本处理工具链。
>
> **目标不是记参数，而是形成“管道式处理文本”的工程直觉。**

---

## 一、grep —— 过滤文本（按模式筛行）

### 1. 核心定义

`grep` = **Global Regular Expression Print**  
核心作用是：**从文本或数据流中筛选出包含指定“模式”的行**。

- 模式可以是**普通字符串**
- 也可以是**正则表达式**

---

### 2. 核心能力

- 按字符串 / 正则筛选行  
- 反向筛选（排除匹配行）  
- 显示行号、仅输出匹配内容等  

---

### 3. 常用参数

| 参数 | 作用                                         |
| ---- | -------------------------------------------- |
| `-i` | 忽略大小写                                   |
| `-v` | 反向匹配（排除匹配行）                       |
| `-n` | 显示行号                                     |
| `-E` | 启用扩展正则（等价于 `egrep`）               |
| `-F` | 固定字符串匹配（不解析正则，等价于 `fgrep`） |

---

### 4. 示例

```bash
# 精确匹配包含 ERROR 的行
grep "ERROR" app.log

# 忽略大小写 + 显示行号
grep -in "error" app.log

# 排除 INFO 日志
grep -v "INFO" app.log

# 使用扩展正则，匹配 WARN 日志行
# 注：日期中的 '.' 是正则字符，这里写成 02.21 依然能匹配
grep -E "^2026-02-21.*WARN" app.log
```

------

## 二、cut —— 切列（按分隔符 / 字符提取字段）

### 1. 核心定义

`cut` 是**结构化文本的“列提取器”**，
 适用于**每一行格式稳定、分隔符明确**的文本。

------

### 2. 核心能力

- 按**字符位置**提取
- 按**分隔符字段**提取

------

### 3. 常用参数

| 参数 | 作用                      |
| ---- | ------------------------- |
| `-d` | 指定分隔符（默认是 `\t`） |
| `-f` | 指定字段编号              |
| `-c` | 按字符位置提取            |

------

### 4. 示例

```bash
# 以冒号为分隔符，提取第一列
cut -d ":" -f1 test.csv
# 从日志中提取 IP 字段
# 先 grep 过滤，再用 cut 切列
grep "IP:" app.log | cut -d " " -f4
```

> 注：
>  `cut` **不会自动压缩连续空格**，
>  对“空格不规整的文本”并不友好，这正是后面 `awk` 更强的原因。

------

## 三、sort / uniq —— 排序与去重（必须成对理解）

### 1. 核心定义

- `sort`：对文本行进行排序
- `uniq`：**仅对相邻重复行生效**

> 结论：**uniq 几乎永远要配合 sort 使用**

------

### 2. 常用参数

| 工具 | 参数 | 作用         |
| ---- | ---- | ------------ |
| sort | `-n` | 数值排序     |
|      | `-r` | 倒序         |
|      | `-k` | 指定排序字段 |
| uniq | `-c` | 统计次数     |
|      | `-d` | 仅显示重复行 |
|      | `-u` | 仅显示唯一行 |

------

### 3. 示例：统计 IP 访问次数

```bash
# 提取 IP 地址并写入文件
grep "IP:" app.log | cut -d " " -f4 | cut -d ":" -f2 > ip_list.txt

# 排序并统计出现次数
sort ip_list.txt | uniq -c
# 只显示出现过多次的 IP
sort ip_list.txt | uniq -d
```

------

## 四、awk —— 按列处理的微型编程语言

### 1. 核心定义

`awk` 不是“命令”，而是**面向行和字段的微型编程语言**：

> 逐行读取 → 按分隔符切列 → 条件判断 → 输出结果

------

### 2. 关键认知

- `$0`：整行

- `$1 ~ $NF`：第 1 列到最后一列

- `-F`：指定分隔符

- 基本结构：

  ```bash
  awk '条件 { 动作 }'
  ```

------

### 3. 示例

```bash
# 以冒号为分隔符，提取用户名和 Shell
awk -F ":" '{print $1, "的shell是", $4}' test.csv
```

> 注：
>  相比 `cut`，`awk` **对空格数量不敏感**，
>  是日志与系统文件处理中最常用的工具。

------

## 五、sed —— 流式文本编辑（非交互）

### 1. 核心定义

`sed` = **Stream Editor**
 特点是：**不打开文件，直接在文本流上修改**

------

### 2. 常见操作

- 替换：`s/旧/新/`
- 删除：`d`
- 插入：`a` / `i`
- 原地修改：`-i`（⚠️ 谨慎）

------

### 3. 示例

```bash
# 仅输出替换后的内容，不改文件
sed 's/ERROR/FATAL/' app.log
# 原地修改，并生成备份文件 app.log.bak
sed -i.bak 's/INFO/DEBUG/g' app.log
```

> 工程习惯建议：
>  **永远优先带备份扩展名**，这是成熟运维与脚本的基本素养。

------

## 附：本文使用的测试文本

```bash
# 创建日志文件 app.log
cat > app.log << EOF
2026-02-21 10:00:00 [INFO] IP:192.168.1.1 访问首页
2026-02-21 10:01:00 [ERROR] IP:192.168.1.2 登录失败
2026-02-21 10:02:00 [WARN] IP:192.168.1.1 密码错误
2026-02-21 10:03:00 [INFO] IP:192.168.1.3 访问商品页
2026-02-21 10:04:00 [ERROR] IP:192.168.1.2 数据库连接失败
2026-02-21 10:05:00 [INFO] IP:192.168.1.1 退出登录
EOF

# 创建结构化测试文件 test.csv
cat > test.csv << EOF
用户名:UID:家目录:登录Shell
root:0:/root:/bin/bash
ikun:1000:/home/ikun:/bin/bash
test:1001:/home/test:/bin/sh
guest:1002:/home/guest:/bin/bash
EOF
```